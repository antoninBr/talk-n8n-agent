<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">


	<meta name="description" content="IA locales ou distantes, outils, et un chef d'orchestre nomm√© n8n">
	<meta name="author" content="Antonin Brugnot">

	<meta name="mobile-web-app-capable" content="yes">
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<title>IA locales ou distantes, outils, et un chef d'orchestre nomm√© n8n</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/codeurs-en-seine.css" id="theme">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<!-- Slide d'introduction -->
			<section>
				<div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 2em; padding: 0 2em;">
					<img src="img/codeurs-en-seine-avatar.svg" alt="Codeurs en Seine" 
						style="max-width: 75px; height: auto; padding: 5px; border-radius: 4px;">
					<img src="img/onepoint-logo.svg" alt="Onepoint" 
						style="max-width: 75px; height: auto; background: white; padding: 5px; border-radius: 4px;">
				</div>
				<div style="text-align: center;">
					<img src="img/title.jpg" alt="Logo"
						style="max-width: 150px; width: 20vw; min-width: 100px; margin-bottom: 1em;">
				</div>
				<h3>IA locales ou distantes, outils, et un chef d'orchestre nomm√© n8n</h3>
				<p>
					<small>Antonin Brugnot - Onepoint</small>
				</p>
				<p style="margin-top: 2em; font-size: 0.8em; color: var(--ces-green);">
					<strong>üìÖ 20 Novembre 2025 - Kindarena, Rouen</strong>
				</p>
				<aside class="notes">
					Bonjour ! Aujourd'hui on va explorer comment orchestrer des agents IA avec n8n, une plateforme
					d'automatisation simple et visuelle. On va connecter des mod√®les IA locaux avec Ollama ou distants,
					et des outils gr√¢ce au protocole MCP. Une approche concr√®te pour cr√©er des assistants IA vraiment
					utiles‚Ä¶ et ma√Ætris√©s.
				</aside>
			</section>

			<!-- Section 1: Pr√©sentation de n8n -->
			<section>
				<section>
					<h1>üîß Pr√©sentation de n8n</h1>
				</section>

				<section>
					<h2>Pourquoi n8n ?</h2>
					<ul>
						<li class="fragment">Connecter vos outils du quotidien</li>
						<li class="fragment">Interface visuelle intuitive</li>
						<li class="fragment">No-code/Low-code (Workflow visuel)</li>
						<li class="fragment">Contr√¥le de vos donn√©es</li>
						<li class="fragment">Open Source</li>
					</ul>
					<aside class="notes">
						n8n permet de connecter facilement tous vos outils : API, bases de donn√©es, services cloud.
						L'interface visuelle rend l'automatisation accessible m√™me aux non-d√©veloppeurs. Et
						contrairement √† Zapier, vous gardez le contr√¥le de vos donn√©es.
					</aside>
				</section>

				<section>
					<div style="text-align: center;">
						<img src="img/war-vietnam.gif" alt="War meme" style="max-width: 70%; margin-bottom: 1em;">
					</div>
					<p style="font-size: 0.8em; font-style: italic;">
						"Tu connais BPMN ?"
					</p>
				</section>


				<section>
					<h2>Self-hosted ou Cloud ?</h2>
					<div style="display: flex; justify-content: space-around;">
						<div style="flex: 1;">
							<h3>üè† Self-hosted</h3>
							<ul>
								<li>Contr√¥le total</li>
								<li>Donn√©es priv√©es</li>
								<li>Personnalisation</li>
								<li>Docker/K8s</li>
							</ul>
						</div>
						<div style="flex: 1;">
							<h3>‚òÅÔ∏è Cloud</h3>
							<ul>
								<li>Simplicit√©</li>
								<li>Maintenance incluse</li>
								<li>Scalabilit√©</li>
								<li>Support officiel</li>
							</ul>
						</div>
					</div>
					<aside class="notes">
						Deux options : self-hosted pour garder le contr√¥le total, ou cloud pour la simplicit√©.
						Aujourd'hui on se concentre sur le self-hosted avec Docker.
					</aside>
				</section>

				<section>
					<h2>Cas d'usage classiques</h2>
					<ul>
						<li class="fragment">Automatisation email</li>
						<li class="fragment">Synchronisation de donn√©es</li>
						<li class="fragment">Rapports automatiques</li>
						<li class="fragment">Notifications intelligentes</li>
						<li class="fragment">Outils internes</li>
					</ul>
					<aside class="notes">
						Les cas d'usage vont de la simple automatisation d'emails √† la cr√©ation d'outils internes
						complexes. Avec l'IA, on peut maintenant cr√©er des workflows vraiment intelligents.
					</aside>
				</section>

				<section>
					<h2>Fonctionnalit√©s cl√©s</h2>
					<ul>
						<li class="fragment">Triggers multiples</li>
						<li class="fragment">Variables entre √©tapes</li>
						<li class="fragment">+400 int√©grations</li>
						<li class="fragment">Gestion d'erreurs</li>
						<li class="fragment">Credentials s√©curis√©s</li>
					</ul>
					<aside class="notes">
						Les triggers d√©clenchent vos workflows : Webhook, Schedule, Email. Les variables permettent de
						passer des donn√©es entre √©tapes. Plus de 400 nodes disponibles pour connecter tous vos outils.
						Gestion d'erreurs robuste avec retry et fallback. Et stockage s√©curis√© des credentials.
					</aside>
				</section>

				<section>
					<h2>Milliers de templates</h2>
					<div style="text-align: center;">
						<img src="img/n8n-workflows.png" alt="Page des workflows n8n" style="max-width: 80%; border: 2px solid #444;">
					</div>
					<p style="margin-top: 1em;">
						üîó <a href="https://n8n.io/workflows/" target="_blank" style="color: var(--ces-green);">n8n.io/workflows/</a>
					</p>
					<p class="fragment" style="font-size: 0.8em; font-style: italic;">
						Pr√™ts √† importer et personnaliser !
					</p>
					<aside class="notes">
						n8n propose des milliers de templates pr√™ts √† l'emploi sur leur site. De l'automatisation email 
						aux int√©grations CRM, en passant par les workflows IA. Un excellent point de d√©part pour vos projets, 
						il suffit d'importer et personnaliser selon vos besoins.
					</aside>
				</section>

				<section>
					<div style="text-align: center;">
						<img src="img/struggle.jpg" alt="Struggle meme" style="max-width: 70%; margin-bottom: 1em;">
					</div>
				</section>

			</section>

			<!-- Section 2: Avec les agents IA -->
			<section>
				<section>
					<h1>ü§ñ Avec les agents IA</h1>
				</section>

				<section>
					<h2>Qu'est-ce qu'un agent IA ?</h2>
					<div style="display: flex; align-items: center; justify-content: space-between; gap: 2em;">
						<div style="flex: 2;">
							<ul>
								<li class="fragment" data-fragment-index="1">üß† <strong>Mod√®le IA</strong> : Le cerveau
									(Krang)</li>
								<li class="fragment" data-fragment-index="2">ü§ñ <strong>Agent</strong> : Le corps cyborg
									qui agit</li>
								<li class="fragment" data-fragment-index="3">üìù <strong>Prompt syst√®me</strong> : Les
									instructions de base</li>
								<li class="fragment" data-fragment-index="4">üõ†Ô∏è <strong>Outils</strong> : Les complices
									(Shredder, Bebop, Rocksteady)</li>
							</ul>
							<p class="fragment" data-fragment-index="5"
								style="font-style: italic; font-size: 0.8em; margin-top: 2em;">
								Agent = Mod√®le + Prompt + Outils
							</p>
						</div>
						<div style="flex: 1;" class="fragment" data-fragment-index="1">
							<img src="img/teenage-mutant-ninja-turtles-cartoon.gif" alt="Krang - Le cerveau mal√©fique"
								style="max-width: 100%; border-radius: 10px; box-shadow: 0 0 20px rgba(255, 0, 255, 0.5);">
							<p style="font-size: 0.6em; font-style: italic; margin-top: 0.5em;">Le cerveau qui orchestre
								tout ! üß†</p>
						</div>
					</div>
					<aside class="notes">
						Un agent IA, c'est comme dans les Tortues Ninja : Krang est le cerveau (le mod√®le IA), le corps
						cyborg c'est l'agent qui peut agir, et ses outils ce sont ses complices Shredder, Bebop et
						Rocksteady qui l'aident √† accomplir ses missions !
					</aside>
				</section>

				<section>
					<h2>AI Agent Node</h2>
					<ul>
						<li class="fragment">Cerveau d√©cisionnel</li>
						<li class="fragment">Prompts syst√®me</li>
						<li class="fragment">Int√©gration native</li>
						<li class="fragment">Planning de t√¢ches</li>
					</ul>
					<aside class="notes">
						L'AI Agent Node est le cerveau de votre workflow. Il peut prendre des d√©cisions, d√©finir son
						comportement via prompts syst√®me, s'int√©grer nativement aux workflows n8n, et planifier des
						actions complexes en les d√©composant selon le contexte.
					</aside>
				</section>

				<section>
					<h2>Configuration des Prompts</h2>
					<div style="display: flex; justify-content: space-around; align-items: flex-start;">
						<div style="flex: 1; margin-right: 2em;">
							<h3>üéØ Prompt Syst√®me</h3>
							<ul style="font-size: 0.7em;">
								<li class="fragment">D√©finit le comportement</li>
								<li class="fragment">Contexte permanent</li>
								<li class="fragment">R√¥le de l'assistant</li>
								<li class="fragment">Contraintes globales</li>
							</ul>
						</div>
						<div style="flex: 1;">
							<h3>üí¨ Prompt Utilisateur</h3>
							<ul style="font-size: 0.7em;">
								<li class="fragment">Instructions sp√©cifiques</li>
								<li class="fragment">Donn√©es contextuelles</li>
								<li class="fragment">Variables dynamiques</li>
								<li class="fragment">Format de sortie</li>
							</ul>
						</div>
					</div>
					<div class="fragment" style="margin-top: 2em; padding: 1em; background: rgba(0,0,0,0.2); border-radius: 8px;">
						<code style="font-size: 0.7em;">
							System: "Tu es un expert technique qui r√©pond de mani√®re claire et pr√©cise."<br>
							User: "Explique comment {{ $json.technology }} fonctionne en {{ $json.level }} phrases."
						</code>
					</div>
					<aside class="notes">
						Dans n8n, vous configurez deux types de prompts. Le prompt syst√®me d√©finit le comportement g√©n√©ral : 
						le r√¥le, le ton, et les contraintes de l'IA. Le prompt utilisateur contient les instructions sp√©cifiques 
						et peut utiliser des variables dynamiques du workflow. Cette s√©paration permet une grande flexibilit√© 
						et r√©utilisabilit√©.
					</aside>
				</section>

				<section>
					<h2>Int√©gration Mod√®les SaaS</h2>
					<div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 1.3em; margin-top: 0.8em;">
						<div class="fragment" style="text-align: center; padding: 1em; background: rgba(0,0,0,0.2); border-radius: 8px;">
							<h3>OpenAI</h3>
							<p style="font-size: 0.6em;">GPT<br>Streaming, Function calling</p>
						</div>
						<div class="fragment" style="text-align: center; padding: 1em; background: rgba(0,0,0,0.2); border-radius: 8px;">
							<h3>Anthropic</h3>
							<p style="font-size: 0.6em;">Claude<br>Analyse de documents</p>
						</div>
						<div class="fragment" style="text-align: center; padding: 1em; background: rgba(0,0,0,0.2); border-radius: 8px;">
							<h3>Google</h3>
							<p style="font-size: 0.6em;">Gemini Pro<br>Multimodal</p>
						</div>
						<div class="fragment" style="text-align: center; padding: 1em; background: rgba(0,0,0,0.2); border-radius: 8px;">
							<h3>Azure</h3>
							<p style="font-size: 0.6em;">OpenAI sur Azure<br>Conformit√© entreprise</p>
						</div>
					</div>
					<div class="fragment" style="margin-top: 1em; text-align: center;">
						<p style="font-size: 0.6em; color: var(--ces-green);">
							‚úÖ <strong>Configuration simple</strong> : API Key + quelques param√®tres
						</p>
					</div>
					<aside class="notes">
						n8n int√®gre nativement les principaux fournisseurs d'IA. OpenAI pour GPT avec streaming et function calling,
						Anthropic pour Claude excellent sur l'analyse de documents, Google pour Gemini et ses capacit√©s multimodales,
						et Azure OpenAI pour les besoins d'entreprise. La configuration est simple : une cl√© API et quelques param√®tres.
					</aside>
				</section>

				<section>
					<h2>Int√©gration Ollama</h2>
					<div style="padding: 1em; background: rgba(0,0,0,0.2); border-radius: 8px; margin-bottom: 1em;">
						<h4>üéØ Configuration n8n</h4>
						<code style="font-size: 0.8em;">
							Base URL: http://ollama:11434 (local)<br>
							Base URL: https://your-server.com:11434 (distant)<br>
							Model: llama3.2, qwen2.5, mistral, codestral...
						</code>
					</div>
					<aside class="notes">
						Ollama est parfait pour l'IA locale. Installation simple, donn√©es priv√©es, pas de co√ªts r√©currents.
						Vous pouvez aussi l'installer sur un serveur distant pour partager les ressources GPU avec votre √©quipe.
						Dans n8n, il suffit de configurer l'URL de base et choisir le mod√®le.
					</aside>
				</section>

				<section>
					<h2>Ollama local vs distant</h2>
					<div style="display: flex; justify-content: space-around;">
						<div style="flex: 1;">
							<h3>üè† Ollama Local</h3>
							<ul>
								<li>Donn√©es priv√©es</li>
								<li>Pas de latence r√©seau</li>
								<li>Pas de co√ªt API</li>
								<li>GPU/CPU local</li>
							</ul>
						</div>
						<div style="flex: 1;">
							<h3>‚òÅÔ∏è Mod√®les distants</h3>
							<ul>
								<li>Performance optimale</li>
								<li>Toujours √† jour</li>
								<li>Scalabilit√©</li>
								<li>Pay-per-use</li>
							</ul>
						</div>
					</div>
					<aside class="notes">
						Ollama permet d'utiliser des mod√®les comme Llama, Qwen, ou Mistral en local. Les mod√®les
						distants offrent plus de puissance mais moins de contr√¥le.
					</aside>
				</section>

				<section>
					<div style="text-align: center;">
						<img src="img/drake.jpg" alt="Drake meme about AI models"
							style="max-width: 80%; margin-bottom: 1em;">
					</div>
					<p style="font-size: 0.8em; font-style: italic;">
						"Il faut faire confiance aux mod√®les distants‚Ä¶"
					</p>
				</section>

				<section>
					<h2>Node Agent en action</h2>
					<img src="img/agent_node.png" alt="Node Agent n8n connect√© √† Ollama"
						style="max-width: 80%; border: 2px solid #444;">
					<p style="font-size: 0.8em; margin-top: 1em;">
						<em>Configuration simple : Agent connect√© √† Ollama local, sans outils ni m√©moire</em>
					</p>
					<aside class="notes">
						Voici un exemple concret d'un node Agent dans n8n. Configuration minimaliste : juste le mod√®le
						Ollama local, sans outils complexes ni m√©moire. Parfait pour commencer et comprendre les bases.
					</aside>
				</section>

				<section>
					<h2>Model Selector</h2>
					<img src="img/model_selector.png" alt="S√©lecteur de mod√®le dynamique dans n8n"
						style="max-width: 40%; border: 2px solid #444;">
					<ul>
						<li class="fragment">Adaptation contextuelle</li>
						<li class="fragment">Basculement automatique</li>
						<li class="fragment">Optimisation co√ªts/perf</li>
					</ul>
					<aside class="notes">
						Cette fonctionnalit√© est tr√®s pratique : on peut changer de mod√®le dynamiquement selon des
						variables, le type de t√¢che, ou impl√©menter des fallbacks si un mod√®le est indisponible. Parfait
						pour optimiser co√ªts et performances selon le contexte.
					</aside>
				</section>

				<section>
					<h2>M√©moire</h2>
					<ul>
						<li class="fragment">Conversation multi-tours</li>
						<li class="fragment">Vector Store (RAG)</li>
						<li class="fragment">Variables persistantes</li>
						<li class="fragment">Historique & apprentissage</li>
					</ul>
					<aside class="notes">
						La m√©moire permet aux agents de maintenir le contexte dans les conversations, d'acc√©der √† une
						base de connaissances via Vector Store pour le RAG, de persister l'√©tat entre workflows, et
						d'apprendre des interactions pr√©c√©dentes gr√¢ce √† l'historique.
					</aside>
				</section>

				<section>
					<h2>Outils disponibles</h2>
					<ul>
						<li class="fragment">Web & APIs</li>
						<li class="fragment">Fichiers & Bases de donn√©es</li>
						<li class="fragment">Communications</li>
						<li class="fragment">Autres agents IA</li>
					</ul>
					<p class="fragment" style="margin-top: 2em; font-size: 0.8em;">
						üí° <em>Via MCP ou int√©grations natives n8n</em>
					</p>
					<aside class="notes">
						Le protocole MCP (Model Context Protocol) permet aux agents d'utiliser des outils externes :
						navigateur web avec Playwright, fichiers, bases de donn√©es SQL/NoSQL/Vectorielles,
						communications Email/Slack/Teams, APIs diverses CRM/ERP/Cloud... et m√™me d'autres agents IA
						sp√©cialis√©s. J'ai une conf√©rence compl√®te sur MCP pour approfondir :
						github.com/antoninBr/talk-mcp
					</aside>
				</section>

				<section>
					<h2>ü§ñ‚û°Ô∏èü§ñ</h2>
					<ul>
						<li class="fragment">Sp√©cialisation par domaine</li>
						<li class="fragment">D√©l√©gation intelligente</li>
						<li class="fragment">√âquilibrage de charge</li>
						<li class="fragment">R√©silience & fallback</li>
					</ul>
					<aside class="notes">
						Un agent peut appeler d'autres agents comme outils : un agent g√©n√©raliste qui d√©l√®gue √† des
						sp√©cialistes (code, r√©daction, analyse). Cela permet une architecture modulaire et r√©siliente en
						microservices, avec √©quilibrage de charge et sp√©cialisation par domaine.
					</aside>
				</section>
				<section>
					<h2>Exemple d'outils</h2>
					<img src="img/tools.png"
						alt="Node Agent avec diff√©rents outils : MCP, Call Workflow n8n, Qdrant Vector Store"
						style="max-width: 80%; border: 2px solid #444;">
					<aside class="notes">
						Voici un exemple concret des outils disponibles pour un agent n8n : MCP pour connecter des
						outils externes, Call Workflow pour orchestrer d'autres workflows, et Qdrant Vector Store pour
						la recherche s√©mantique. Une palette compl√®te pour cr√©er des agents polyvalents.
					</aside>
				</section>

				<section>
					<h2>Interface Chat : Embedded vs Hosted</h2>
					<img src="img/chat_trigger.png" alt="Trigger Chat : modes embedded et hosted"
						style="max-width: 80%; border: 2px solid #444;">
					<div style="display: flex; justify-content: space-around; margin-top: 1em;">
						<div style="flex: 1;">
							<h4>üè† Embedded</h4>
							<ul style="font-size: 0.8em;">
								<li>Widget int√©gr√©</li>
								<li>Votre design</li>
								<li>Contr√¥le total</li>
							</ul>
						</div>
						<div style="flex: 1;">
							<h4>‚òÅÔ∏è Hosted</h4>
							<ul style="font-size: 0.8em;">
								<li>Page d√©di√©e</li>
								<li>Pr√™t √† l'emploi</li>
								<li>D√©ploiement rapide</li>
							</ul>
						</div>
					</div>
					<aside class="notes">
						n8n propose deux modes d'interaction avec vos agents : embedded pour int√©grer le chat dans vos
						applications existantes avec votre propre design, ou hosted pour une page de chat d√©di√©e et
						pr√™te √† l'emploi. Parfait pour tester rapidement ou d√©ployer un chatbot interne.
					</aside>
				</section>

				<section>
					<h2>Architecture compl√®te</h2>
					<div class="mermaid"><pre>
						graph TB
							User[üë§ Utilisateur] --> Chat[üí¨ Interface Chat]
							Chat --> N8N[üîß n8n]
							N8N --> PG[(üóÑÔ∏è PostgreSQL)]
							N8N --> Agent[ü§ñ AI Agent]
							Agent --> Ollama[üß† Ollama LLMs locaux]
							Agent --> Qdrant[üîç Qdrant Vector DB]
							Agent --> MCP[üé≠ Playwright MCP]
							Agent --> API[üß† OpenAI LLMs]

							subgraph "üê≥ Docker Compose Stack"
								Chat
								N8N
								PG
								Ollama
								Qdrant
								MCP
								Agent
							end
							
							style User fill:#e1f5fe
							style Chat fill:#f3e5f5
							style N8N fill:#e8f5e8
							style Agent fill:#fff3e0
							style Ollama fill:#fce4ec
							style API fill:#fce4ec
							style MCP fill:#fce4ec
							style Qdrant fill:#f1f8e9
							style PG fill:#e3f2fd
					</pre>
					</div>
					<aside class="notes">
						Architecture locale compl√®te avec Docker Compose : interface chat, n8n comme orchestrateur, 
						agent IA connect√© √† Ollama pour les LLMs et Qdrant pour la recherche vectorielle, 
						le tout persist√© en PostgreSQL.
					</aside>
				</section>
			</section>
			<!-- Section 3: D√©mo live -->
			<section>
				<section>
					<h1>üöÄ D√©mo live : n8n sandbox</h1>
				</section>

				<section>
					<h2>Docker compose : stack complet</h2>
					<pre><code class="hljs yaml" data-trim data-line-numbers="|1-43|2-11|13-30|32-39|41-43">
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: n8n
      POSTGRES_USER: n8n
      POSTGRES_PASSWORD: n8n
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  n8n:
    build: ./n8n
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=n8n
      - DB_POSTGRESDB_PASSWORD=n8n
      - N8N_HOST=localhost
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
    ports:
      - "5678:5678"
    volumes:
      - n8n_data:/home/node/.n8n
    depends_on:
      - postgres

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11435:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434

volumes:
  postgres_data:
  n8n_data:
  ollama_data:
					</code></pre>
					<aside class="notes">
						Stack complet avec PostgreSQL pour la persistence, n8n comme chef d'orchestre, et Ollama pour
						l'IA locale. Utilisez les fl√®ches pour naviguer et voir chaque service mis en focus.
					</aside>
				</section>

				<section>
					<h2>üê≥ Docker Model Runner</h2>
					<pre><code class="hljs yaml" data-trim data-line-numbers="|1-19|2-8|10-19">
# Version avec Docker Model Runner (Docker Compose)
services:
  n8n:
    build: ./n8n
    ports:
      - "5678:5678"
    models:
      - llm

models:
  llm:
    model: ollama/llama3.2:3b
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
    ports:
      - "11435:11434"
    volumes:
      - ollama_data:/root/.ollama
    runtime: ollama
				</code></pre>
					<aside class="notes">
						Docker Model Runner simplifie la syntaxe pour d√©ployer des mod√®les IA avec Docker Compose. Plus
						lisible et automatis√©, mais encore limit√© √† Docker Compose. Utilisez les fl√®ches pour naviguer :
						vue d'ensemble, service n8n, puis section models. Pour la compatibilit√© Podman, on reste sur les
						services classiques.
					</aside>
				</section>

				<section>
					<h2>‚ú® Avantages</h2>
					<ul>
						<li class="fragment">Syntaxe simplifi√©e</li>
						<li class="fragment">Liaison automatique n8n ‚Üî mod√®le</li>
						<li class="fragment">Configuration centralis√©e</li>
						<li class="fragment">D√©ploiement unifi√©</li>
					</ul>
					<aside class="notes">
						Les avantages du Docker Model Runner : syntaxe plus claire, liaison automatique entre n8n et les
						mod√®les, toute la config au m√™me endroit, et d√©ploiement en une seule commande.
					</aside>
				</section>

				<section>
					<h2>‚ö†Ô∏è Limitations</h2>
					<ul>
						<li class="fragment">Docker Compose uniquement</li>
						<li class="fragment">Fonctionnalit√© r√©cente</li>
						<li class="fragment">Documentation limit√©e</li>
						<li class="fragment">Fallback classique recommand√©</li>
					</ul>
					<aside class="notes">
						Attention aux limitations : pas encore compatible Podman, fonctionnalit√© r√©cente donc
						potentiellement instable, peu de documentation disponible. Pour la production, pr√©f√©rez la
						configuration classique avec services s√©par√©s.
					</aside>
				</section>

				<section>
					<h2>Les workflows</h2>
					<ul>
						<li class="fragment">üìß <strong>Mail.json</strong> : Assistant email intelligent</li>
						<li class="fragment">üóÇÔ∏è <strong>Indexation.json</strong> : Traitement de documents</li>
						<li class="fragment">üí¨ <strong>Chat.json</strong> : Chatbot</li>
					</ul>
				</section>

				<section>
					<h2>Demo time! üé¨</h2>
					<h3>D√©marrage de la stack</h3>
					<pre><code class="hljs bash" data-trim>
						# Lancement des services
						./start.sh

						# Configuration d'Ollama local
						./setup-ollama.sh

						# Import des workflows
						./import-n8n-data.sh
						</code></pre>
					<aside class="notes">
						Maintenant, place √† la d√©mo ! On va d√©marrer le stack, configurer Ollama avec des mod√®les
						locaux, et importer nos workflows.
					</aside>
				</section>

				<section data-background="lightblue">
					<h1>üéØ D√©mo en direct</h1>
					<p>http://localhost:5678</p>
					<aside class="notes">
						[Ici, faire la d√©monstration live des workflows]
					</aside>
				</section>
			</section>

			<!-- Section Sponsors -->
			<section>
				<section>
					<h1>üôè Merci √† nos sponsors</h1>
					<p style="font-size: 0.8em;">Codeurs en Seine 2025 ne pourrait exister sans le soutien de nos partenaires</p>
				</section>

				<section>
					<h2>Sponsors Platine & Or</h2>
					<div class="sponsors-grid">
						<div class="sponsor-logo">
							<img src="img/sponsors/attineos.png" alt="Attineos">
						</div>
						<div class="sponsor-logo">
							<img src="img/sponsors/bluesoft.png" alt="BlueSoft">
						</div>
						<div class="sponsor-logo">
							<img src="img/sponsors/digit.png" alt="Digit">
						</div>
						<div class="sponsor-logo">
							<img src="img/sponsors/leboncoin.png" alt="Le Bon Coin">
						</div>
						<div class="sponsor-logo">
							<img src="img/sponsors/matmut.png" alt="Matmut">
						</div>
						<div class="sponsor-logo">
							<img src="img/sponsors/sqli.png" alt="SQLI">
						</div>
					</div>
					<aside class="notes">
						Un grand merci √† nos sponsors principaux qui rendent cet √©v√©nement possible : Attineos, BlueSoft, Digit, Le Bon Coin, Matmut et SQLI.
					</aside>
				</section>

				<section>
					<h2>Sponsors Argent & Bronze</h2>
					<div class="sponsors-grid">
						<div class="sponsor-logo">
							<img src="img/sponsors/imagile.png" alt="Imagile">
						</div>
						<div class="sponsor-logo">
							<img src="img/sponsors/limops.png" alt="LimOps">
						</div>
						<div class="sponsor-logo">
							<img src="img/sponsors/magnolia.png" alt="Magnolia">
						</div>
						<div class="sponsor-logo">
							<img src="img/sponsors/proxiad.png" alt="Proxiad">
						</div>
						<div class="sponsor-logo">
							<img src="img/sponsors/redlab.png" alt="REDLab">
						</div>
						<div class="sponsor-logo">
							<img src="img/sponsors/wixiweb.png" alt="Wixiweb">
						</div>
					</div>
					<aside class="notes">
						Merci √©galement √† nos autres sponsors : Imagile, LimOps, Magnolia, Proxiad, REDLab et Wixiweb.
					</aside>
				</section>

				<section>
					<h2>Partenaires Institutionnels & √âducatifs</h2>
					<div class="sponsors-grid">
						<div class="sponsor-logo">
							<img src="img/sponsors/metropole-rouen-normandie.png" alt="M√©tropole Rouen Normandie">
						</div>
						<div class="sponsor-logo">
							<img src="img/sponsors/cesi.png" alt="CESI">
						</div>
						<div class="sponsor-logo">
							<img src="img/sponsors/nfs.png" alt="Need For School">
						</div>
					</div>
					<aside class="notes">
						Enfin, merci √† nos partenaires institutionnels et √©ducatifs : la M√©tropole Rouen Normandie, le CESI et Need For School. Rendez-vous le 20 novembre 2025 !
					</aside>
				</section>
			</section>

			<!-- Section 4: Conclusion et questions -->
			<section>
				<section>
					<h1>‚ùì Conclusion et questions</h1>
				</section>

				<section>
					<h2>Ce qu'on a vu</h2>
					<ul>
						<li class="fragment">‚úÖ n8n comme chef d'orchestre</li>
						<li class="fragment">‚úÖ Int√©gration IA locale (Ollama) et distante</li>
						<li class="fragment">‚úÖ Agents avec m√©moire et outils</li>
						<li class="fragment">‚úÖ Protocole MCP pour √©tendre les capacit√©s</li>
						<li class="fragment">‚úÖ D√©mo concr√®te avec workflows</li>
					</ul>
					<aside class="notes">
						R√©cap de ce qu'on a couvert : n8n comme plateforme centrale, IA locale et distante, agents
						intelligents avec m√©moire et outils, et une d√©mo pratique.
					</aside>
				</section>

				<section>
					<h2>Pour aller plus loin</h2>
					<ul>
						<li class="fragment">üîó <strong>Sources</strong> : GitHub avec docker-compose</li>
						<li class="fragment">üìö <strong>Documentation</strong> : n8n.io et ollama.ai</li>
						<li class="fragment">üåê <strong>Communaut√©</strong> : Discord n8n et forums</li>
						<li class="fragment">üöÄ <strong>√âvolutions</strong> : Nouveaux nodes IA en permanence</li>
					</ul>
					<aside class="notes">
						Pour continuer : toutes les sources sont disponibles, la doc officielle est excellente, et la
						communaut√© tr√®s active.
					</aside>
				</section>

				<section>
					<h2 class="r-fit-text">Questions ? ü§î</h2>
					<p class="fragment">Merci pour votre attention !</p>
				</section>

				<section data-auto-animate>
					<h2 data-id="code-title">bio.yaml</h2>
					<pre data-id="code-animation"><code class="hljs yaml" data-trim data-line-numbers><script type="text/template">
							first_name: "Antonin"
							family_name: "Brugnot"
							company: "Onepoint"
							twitter: null
							personal_info:
							  email: "a.brugnot@groupeonepoint.com"
							  birth: "21st July, 1987"
							  photo: "tronche_joviale.png"
							  location: "Nantes"
							summary: "Lead Tech, DevOps, FullStack, Cloud, IA"
						</script></code></pre>
				</section>

				<section>
					<h2>Contact & Sources</h2>
					<p>üìß a.brugnot@groupeonepoint.com</p>
					<p>üîó GitHub : antoninBr/talk-n8n-agent</p>
					<p>üè¢ Onepoint - Nantes</p>
				</section>
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/mermaid/mermaid.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			controls: true,
			progress: true,
			center: true,
			hash: true,
			slideNumber: true,
			// mermaid initialize config
			mermaid: {
				// flowchart: {
				//   curve: 'linear',
				// },
			},
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealNotes, RevealMarkdown, RevealHighlight, RevealMermaid]
		});
	</script>
</body>

</html>