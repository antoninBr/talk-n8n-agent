# ğŸ¤ Talk n8n Agent - IA locales ou distantes, outils, et un chef d'orchestre nommÃ© n8n

DÃ©mo et prÃ©sentation sur l'orchestration d'agents IA avec n8n.

## ğŸ“ Ã€ propos

Cette dÃ©monstration illustre comment crÃ©er un assistant IA intelligent en orchestrant des modÃ¨les locaux et distants avec n8n, incluant :

- ğŸ¤– **Chat assistant** avec streaming en temps rÃ©el
- ğŸ“š **SystÃ¨me RAG** (Retrieval-Augmented Generation) avec Qdrant
- ğŸ”§ **Interface d'administration** pour la gestion des donnÃ©es
- ğŸ‹ **Stack complÃ¨te dockerisÃ©e** pour un dÃ©ploiement facile

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Chat Web UI   â”‚    â”‚      n8n        â”‚    â”‚    Qdrant       â”‚
â”‚   (Nginx:8080)  â”‚â—„â”€â”€â–ºâ”‚   (Port 5678)   â”‚â—„â”€â”€â–ºâ”‚  Vector Store   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   PostgreSQL    â”‚
                       â”‚   (Stockage)    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚     Ollama      â”‚
                       â”‚  (IA locale)    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ DÃ©marrage rapide

### PrÃ©requis

- Docker & Docker Compose
- 8 Go de RAM minimum (recommandÃ©: 16 Go)
- 10 Go d'espace disque libre

### 1. Cloner et configurer

```bash
git clone https://github.com/antoninBr/talk-n8n-agent.git
cd talk-n8n-agent

# GÃ©nÃ©rer les clÃ©s et configuration
./generate-key.sh
```

### 2. Lancer la stack complÃ¨te

```bash
# DÃ©marrage automatique avec script
./start.sh

# OU dÃ©marrage manuel
docker compose up -d
```

### 3. AccÃ©der aux services

- **ğŸ¨ Chat Assistant** : http://localhost:8443 ou http://localhost:8080
- **âš™ï¸ Interface n8n** : http://localhost:5678
- **ğŸ“Š Qdrant** : http://localhost:6333
- **ğŸ“Š Ollama** : http://localhost:11435

### 4. Import des workflows (optionnel)

```bash
# Importer les workflows n8n prÃ©configurÃ©s
./import-n8n-data.sh
```

## ğŸ“ Structure du projet

```
â”œâ”€â”€ ğŸ“± chat_app/              # Interface web du chat assistant
â”œâ”€â”€ ğŸ“Š docs/                  # Slides de prÃ©sentation (Reveal.js)
â”œâ”€â”€ ğŸ—ƒï¸ vector-store-qdrant/   # Configuration Qdrant
â”œâ”€â”€ ğŸ”§ workflows/             # Workflows n8n
â”œâ”€â”€ ğŸ”‘ credentials/           # Credentials n8n (Ollama, Qdrant)
â”œâ”€â”€ ğŸ‹ docker-compose.yml     # Stack complÃ¨te
â””â”€â”€ ğŸ“œ                        # start.sh, stop.sh, clean.sh...
```

## ğŸ¯ FonctionnalitÃ©s dÃ©montrÃ©es

### ğŸ’¬ Assistant Chat
- Streaming en temps rÃ©el
- Gestion de sessions
- Choix du modÃ¨le IA (local/distant)
- Interface moderne et responsive

### ğŸ§  SystÃ¨me RAG
- **Upload de documents** : PDF, TXT
- **Web scraping** : Extraction automatique de contenu web
- **Base vectorielle** : Stockage et recherche sÃ©mantique avec Qdrant
- **Collections management** : Interface de gestion des donnÃ©es

### ğŸ”§ Administration
- Monitoring des collections Qdrant
- Gestion des documents indexÃ©s
- Interface d'administration intÃ©grÃ©e

## ğŸ¤ Slides de prÃ©sentation

Les slides sont disponibles dans le dossier `/docs` et utilisent Reveal.js.

**Sujet** : "IA locales ou distantes, outils, et un chef d'orchestre nommÃ© n8n"

**Contenu** :
- Introduction aux agents IA
- Orchestration avec n8n
- DÃ©monstration live du systÃ¨me RAG
- Bonnes pratiques et retours d'expÃ©rience

## âš™ï¸ Configuration avancÃ©e

### Variables d'environnement

Copiez `.env.example` vers `.env` et ajustez :

```bash
# Base de donnÃ©es
POSTGRES_DB=n8n
POSTGRES_USER=n8n
POSTGRES_PASSWORD=n8n

# n8n
N8N_BASIC_AUTH_ACTIVE=true
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_PASSWORD=admin

# Qdrant
QDRANT_API_KEY=your-api-key-here
```

### ModÃ¨les IA supportÃ©s

- **Local** : Ollama (llama2, mistral, codellama...)
- **Distant** : OpenAI GPT, Anthropic Claude, etc.

## ğŸ› ï¸ Scripts utiles

```bash
# DÃ©marrer la stack
./start.sh

# ArrÃªter la stack
./stop.sh

# Nettoyer complÃ¨tement (attention: supprime les donnÃ©es)
./clean.sh

# Configurer les collections Qdrant
./setup-collections.sh

# Configurer Ollama avec modÃ¨les
./setup-ollama.sh
```

## ğŸ“š Documentation dÃ©taillÃ©e

- **Chat App** : Voir [chat_app/README.md](./chat_app/README.md)
- **Workflows n8n** : Documentation dans l'interface n8n
- **Configuration Qdrant** : [vector-store-qdrant/](./vector-store-qdrant/)

## ğŸ› DÃ©pannage

### Services qui ne dÃ©marrent pas
```bash
# VÃ©rifier les logs
docker compose logs

# RedÃ©marrer un service spÃ©cifique
docker compose restart n8n
```

### ProblÃ¨mes de mÃ©moire
- Ollama nÃ©cessite minimum 4 Go de RAM
- Ajustez les modÃ¨les selon votre configuration

### Port dÃ©jÃ  utilisÃ©
```bash
# Changer les ports dans docker-compose.yml
# Par dÃ©faut: 8080 et 8443 (chat), 5678 (n8n), 11435 (slides)
```

## ğŸ¤ Contribution

Cette dÃ©mo est conÃ§ue pour Ãªtre Ã©ducative et facilement adaptable. N'hÃ©sitez pas Ã  :

- Forker le projet
- Adapter les workflows Ã  vos besoins
- Contribuer aux amÃ©liorations

## ğŸ“„ Licence

MIT License - Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

**PrÃ©sentÃ© Ã  Codeurs en Seine 2025**  
Par [Antonin Brugnot](https://github.com/antoninBr)  

ğŸ”— **Liens utiles** :
- [n8n Documentation](https://docs.n8n.io/)
- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [Ollama Models](https://ollama.ai/library)